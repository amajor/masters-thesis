\chapter{Results} \label{chapterResults}

% Results, findings, discussion of results OR manuscripts.  It is best to also reiterate information in your literature review to help substantiate the findings of your research.

With our narrowed focus of repositories, we can now spend some more efforts looking through the data that can be collected. Specifically, we gathered data on the Refactor Warnings provided by Pylint. In Table \ref{table:smallRefactorWarningTotals} we have a shortened listing of the repositories from our set with their total count of refactor warning messages, in addition to the most commonly appearing refactor warning message. For the entire set, see Table \ref{table:allRefactorWarningTotals} in the Appendix.

\begin{table}[ht]
  \small
  \centering
  \begin{tabularx}{0.8\textwidth} {
    | l 
    | c
    | >{\centering\arraybackslash}X 
    | c |
  }
    \hline
    Repository Name & Msg Count & Top Msg & Top Msg Count \\
    \hline\hline
    sympy & 14,206 & too-many-arguments & 6,601 (46\%) \\ \hline
    ansible &  10,431 & no-else-return & 1,711 (16\%) \\ \hline
    salt &  7,814 & too-many-arguments & 1,640 (21\%) \\ \hline
    -- & -- & -- & -- \\ \hline
    ranger & 109 & no-else-return & 29 (27\%) \\ \hline
    sentry & 66 & no-self-use & 32 (48\%) \\ \hline
    raven-python & 20 & too-few-public-methods & 7 (35\%) \\ \hline
  \end{tabularx}
  \caption{Total refactor messages per repository for the 3 best and 3 worst offendors. Also provided with the refactor message that had the most warnings and its total count (and the percentage of that message from the total refactor warnings for that repository).}
  \label{table:smallRefactorWarningTotals}
\end{table}

We can see that the ``worst'' project in our set, in regards to the number of refactor warning messages provided, was the repository Sympy \cite{data:sympy}, with 14,206 refactor messages. However, project size may also weigh into how many warnings and errors are present, as larger projects are presumed to have more errors.

If we instead look at the ratio of refactor warnings to the total lines of source code, we get a very different picture, provided in Table \ref{table:smallRefactorSLOCRatio}. In this case, the repository Raven-Python \cite{data:raven-python} (which was the ``best'' in regards to refactor message count) is the ``worst'' with the highest ratio of refactoring warnings compared to the lines of source code in the project. Raven-Python also has the smallest count of SLOC in the entire repository set!

\begin{table}[ht]
  \small
  \centering
  \begin{tabularx}{1.0\textwidth} {
    | l 
    | r
    | r
    | >{\centering\arraybackslash}X |
  }
    \hline
    Repository & Total Refactor Msgs & Total Project SLOC & Ratio \\
    \hline\hline
    raven-python & 20 & 1,474 & 1.35 \\ \hline
    scrapy & 381 & 58,768 & 0.64 \\ \hline
    numba & 126 & 20,192 & 0.62 \\ \hline
    -- & -- & -- & -- \\ \hline
    electrum & 722 & 425,576 & 0.16 \\ \hline
    youtube-dl & 1,003 & 667,075 & 0.15 \\ \hline
    cython & 1,718 & 1,183,863 & 0.14 \\ \hline
  \end{tabularx}
  \caption{Total refactor messages per repository, total project source line of code (SLOC), and the ratio of refactor messages to SLOC.}
  \label{table:smallRefactorSLOCRatio}
\end{table}

Given that we now have an idea of which projects have the most refactor messages per lines of source code (``worst'' offenders) and the projects with the least refactor messages (``best'' projects for maintainability), we can look a little closer at the messages that are most frequent. Common to all six of these repositories at a high frequency are the message ``no-self-use'' and ``no-else-return''. The message ``no-self-use'' means that `self' is used as an argument but is not used in the method and should be handled differently. The message ``no-else-return'' highlights when an unnecessary block of code follows an if-conditional.

Some of the other common messages call out the use of ``too many'' of different types of objects. For example, ``too-many-branches'', ``too-many-arguments'', ``too-many-locals'', ``too-many-statements''... 

\vspace{0.25cm}
\begin{displayquote}
  ``Software maintainability these days has become one of the essential external attributes of software, which further forms a basis of research for many researchers working in the fields related to software engineering. Software maintainability can be described as the extent to which a particular software system can be changed concerning the number of Lines of Code (LOC).'' \cite{gupta:2021}
\end{displayquote}
\vspace{0.25cm}

Now, it would be helpful to understand where we stand on the Maintainability Index (MI) for these projects, as this is our form of measurement that will help us understand how the code might be able to evolve over time. The MI is calculated on a per-module basis, but for the sake of conversation (and acknowledging that we will lose some nuances by reducing it this way), let's find the average MI at the project level and add this to our table (Table \ref{table:smallRefactorSLOCRatio2}).

\begin{table}[ht]
  \small
  \centering
  \begin{tabularx}{1.0\textwidth} {
    | l 
    | r
    | r
    | r
    | >{\centering\arraybackslash}X |
  }
    \hline
    Repo & Refactor Msgs & Project SLOC & Ratio & Avg Project MI \\
    \hline\hline
    raven-python & 20 & 1474 & 1.35 & 87.02 \\ \hline
    scrapy & 381 & 58768 & 0.64 & 64.47 \\ \hline
    numba & 126 & 20192 & 0.62 & 62.55 \\ \hline
    -- & -- & -- & -- & -- \\ \hline
    electrum & 722 & 425576 & 0.16 & 39.41 \\ \hline
    youtube-dl & 1003 & 667075 & 0.15 & 54.16 \\ \hline
    cython & 1718 & 1183863 & 0.14 & 31.02 \\ \hline
  \end{tabularx}
  \caption{Total refactor messages per repository, total project source line of code (SLOC), the ratio of refactor messages to SLOC, average Maintainability Index (MI).}
  \label{table:smallRefactorSLOCRatio2}
\end{table}

When reviewing the MI for our repositories at either end of the spectrum and in context with the entire set (see Appendex \ref{table:allRefactorSLOCRatio}), we'll find that while Raven-Python has the highest number of refactor warnings when compared to the SLOC count, it also has the second highest average MI across all of its project files.

Of the full set, our highest average MI is 87.38 (belonging to Sentry) and our lowest average MI is 28.85 (belonging to MatPlotLib). Regardless, all of these average values are above a score of 20, which is Radon's lowest score provided for an ``A'' rank, that is, what would be considered a project ``very high'' maintainability.
